{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from src import Value\n",
    "from src import draw_dot, trace\n",
    "from src import MLP \n",
    "from sklearn.datasets import load_iris\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "\n",
    "def normalize(data: list):\n",
    "    min_values = np.min(data, axis=0)\n",
    "    max_values = np.max(data, axis=0)\n",
    "    return (data - min_values) / (max_values - min_values)\n",
    "\n",
    "\n",
    "combined_data = list(zip(normalize(iris.data), normalize(iris.target)))\n",
    "random.shuffle(combined_data)\n",
    "shx, shy = zip(*combined_data)\n",
    "X, y = list([list(x) for x in shx]), list(shy)\n",
    "\n",
    "\n",
    "training_data_percent = 0.80\n",
    "training_size = int(len(X) * training_data_percent)\n",
    "testing_size = len(X) - training_size\n",
    "training_data_points, training_targets = X[:training_size], y[:training_size]\n",
    "testing_data_points, testing_targets = X[-testing_size:], y[-testing_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, 1.0],\n",
    "    [-3.0, -1.0, 1.0],\n",
    "    [1.0, -1.0, 1.0],\n",
    "    [-2.0, -1.0,7.0]\n",
    "]\n",
    "\n",
    "expected_ys = [-1.0, -1.0, 1.0, -1.0]\n",
    "\n",
    "number_of_inputs = len(xs[0])\n",
    "number_of_outputs_for_each_layer = [4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(len(xs[0]), number_of_outputs_for_each_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  [Value(data=0.5679153773394316), Value(data=-0.8555585127956113), Value(data=0.6547846278474171), Value(data=-0.8965969044921079)]\n",
      "loss:  Value(data=2.6090878270543287)\n",
      "actual:  [Value(data=0.43522756160561654), Value(data=-0.8463554770528474), Value(data=0.6721369394275357), Value(data=-0.8949429156134673)]\n",
      "loss:  Value(data=2.202015970491804)\n",
      "actual:  [Value(data=0.24021258534344433), Value(data=-0.8354233080884382), Value(data=0.6867294541043284), Value(data=-0.8938436001867676)]\n",
      "loss:  Value(data=1.674620360511902)\n",
      "actual:  [Value(data=-0.019012319726789427), Value(data=-0.8230903740946839), Value(data=0.6981217034047004), Value(data=-0.8937091340111746)]\n",
      "loss:  Value(data=1.0960620987337077)\n",
      "actual:  [Value(data=-0.27923863467476895), Value(data=-0.81140383627478), Value(data=0.7062760160331538), Value(data=-0.8947562903494484)]\n",
      "loss:  Value(data=0.6524154758957269)\n",
      "actual:  [Value(data=-0.4600696996709668), Value(data=-0.8031297062698214), Value(data=0.7125150476717131), Value(data=-0.8965042959538544)]\n",
      "loss:  Value(data=0.42364160033801157)\n",
      "actual:  [Value(data=-0.5669952241590845), Value(data=-0.7984035084468856), Value(data=0.7181931660033662), Value(data=-0.89835920043357)]\n",
      "loss:  Value(data=0.3178802251312759)\n",
      "actual:  [Value(data=-0.6331092381085707), Value(data=-0.7960043182925135), Value(data=0.7236968763900815), Value(data=-0.9001335523547753)]\n",
      "loss:  Value(data=0.2625397927984499)\n",
      "actual:  [Value(data=-0.677488552576658), Value(data=-0.7950478114593207), Value(data=0.7290534606837122), Value(data=-0.9018079038925745)]\n",
      "loss:  Value(data=0.22907274821215584)\n",
      "actual:  [Value(data=-0.7093678612142729), Value(data=-0.7950221503351576), Value(data=0.7342407895536537), Value(data=-0.9033921910258234)]\n",
      "loss:  Value(data=0.2064439856402453)\n"
     ]
    }
   ],
   "source": [
    "number_of_epoch = 10\n",
    "for i in range(number_of_epoch):\n",
    "    # Forward pass\n",
    "    actual_ys = [mlp(x)[0] for x in xs]\n",
    "    print(\"actual: \", actual_ys)\n",
    "    loss: Value = sum((expected_y - actual_y)**2 for expected_y, actual_y in zip(expected_ys, actual_ys))\n",
    "    loss\n",
    "    print(\"loss: \", loss)\n",
    "\n",
    "    # zero grad\n",
    "    for p in mlp.parameters():\n",
    "        p.grad = 0.0\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Correcting parameters\n",
    "    for p in mlp.parameters():\n",
    "        p.data += -0.01 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.2064439856402453)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss: Value = sum((expected_y - actual_y)**2 for expected_y, actual_y in zip(expected_ys, actual_ys))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.2064439856402453)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in mlp.parameters():\n",
    "    p.data += -0.01 * p.grad\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.2064439856402453)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.svg'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(pix:16108): GLib-GObject-WARNING **: 18:28:13.962: g_type_class_add_private() called multiple times for the same type\n"
     ]
    }
   ],
   "source": [
    "draw_dot(loss).view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
