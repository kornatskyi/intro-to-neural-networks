# Intro to Neural Networks ðŸ’¡ðŸ§ 

This repository contains Python code and Jupyter notebooks that explore the basics of building and training small neural networks, inspired by Andrej Karpathy's video tutorial ["The spelled-out intro to neural networks and backpropagation: building micrograd"](https://youtu.be/cRTq1Wj9yL0).

The project is structured into source files (`src`), Jupyter notebooks, and test files (`tests`). The code is written in Python, and the training and demonstration of neural networks are done through Jupyter notebooks.

## ðŸ“š Usage

See usage example in `Train_model_on_iris_data.ipynb` file.

## ðŸš€ Getting Started

1. Clone this repository.
2. Install the required packages using `pip install -r requirements.txt`.
3. Open and run the Jupyter notebooks to explore the neural network examples.
4. Check the source code in the `src` folder to learn more about the implementation details.
5. Run the tests in the `tests` folder to ensure everything is working correctly.
6. If you want to pull micrograd submodule repo to test example against it run `git submodule update --init --recursive`