{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Set up the figure, the axis, and the plot element we want to animate\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Game of Life setup\n",
    "N = 10  # Size of the grid\n",
    "ON = 255  # cells that are alive\n",
    "OFF = 0  # cells that are dead\n",
    "vals = [ON, OFF]\n",
    "\n",
    "# populate grid with random on/off - more off than on\n",
    "grid = np.random.choice(vals, N*N, p=[0.2, 0.8]).reshape(N, N)\n",
    "# Correcting the code to define 'img' before using it in FuncAnimation\n",
    "\n",
    "# # Initialize the plot with the initial grid state\n",
    "# img = ax.imshow(grid, interpolation='nearest', cmap='gray_r')\n",
    "\n",
    "# def update(frameNum, img, grid, N):\n",
    "#     # copy grid since we require 8 neighbors for calculation\n",
    "#     # and we go line by line \n",
    "#     newGrid = grid.copy()\n",
    "#     for i in range(N):\n",
    "#         for j in range(N):\n",
    "#             # compute 8-neighbor sum using toroidal boundary conditions\n",
    "#             total = int((grid[i, (j-1)%N] + grid[i, (j+1)%N] +\n",
    "#                          grid[(i-1)%N, j] + grid[(i+1)%N, j] +\n",
    "#                          grid[(i-1)%N, (j-1)%N] + grid[(i-1)%N, (j+1)%N] +\n",
    "#                          grid[(i+1)%N, (j-1)%N] + grid[(i+1)%N, (j+1)%N])/255)\n",
    "            \n",
    "#             # apply Conway's rules\n",
    "#             if grid[i, j]  == ON:\n",
    "#                 if (total < 2) or (total > 3):\n",
    "#                     newGrid[i, j] = OFF\n",
    "#             else:\n",
    "#                 if total == 3:\n",
    "#                     newGrid[i, j] = ON\n",
    "\n",
    "#     # update data\n",
    "#     img.set_data(newGrid)\n",
    "#     grid[:] = newGrid[:]\n",
    "#     return img,\n",
    "\n",
    "# # Set up the animation\n",
    "# ani = FuncAnimation(fig, update, fargs=(img, grid, N),\n",
    "#                     frames=100,\n",
    "#                     interval=200,\n",
    "#                     save_count=50)\n",
    "\n",
    "# # To display the animation in a Jupyter notebook, we need to use HTML\n",
    "# from IPython.display import HTML\n",
    "# plt.close()  # Prevents the initial static plot from displaying\n",
    "\n",
    "# # Convert the animation to HTML and display it in the notebook\n",
    "# HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gol/training_data.csv', './gol/testing_data.csv')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to evolve the grid by one step according to Conway's rules\n",
    "def evolve_grid(grid, N):\n",
    "    new_grid = grid.copy()\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            total = int(\n",
    "                (\n",
    "                    grid[i, (j - 1) % N]\n",
    "                    + grid[i, (j + 1) % N]\n",
    "                    + grid[(i - 1) % N, j]\n",
    "                    + grid[(i + 1) % N, j]\n",
    "                    + grid[(i - 1) % N, (j - 1) % N]\n",
    "                    + grid[(i - 1) % N, (j + 1) % N]\n",
    "                    + grid[(i + 1) % N, (j - 1) % N]\n",
    "                    + grid[(i + 1) % N, (j + 1) % N]\n",
    "                )\n",
    "                / 255\n",
    "            )\n",
    "\n",
    "            if grid[i, j] == ON:\n",
    "                if (total < 2) or (total > 3):\n",
    "                    new_grid[i, j] = OFF\n",
    "            else:\n",
    "                if total == 3:\n",
    "                    new_grid[i, j] = ON\n",
    "    return new_grid\n",
    "\n",
    "\n",
    "# Generate data for training and testing\n",
    "def generate_data(num_instances, grid_size, filename):\n",
    "    data = []\n",
    "    for init in [(0.2, 0.8), (0.5, 0.5), (0.7, 0.3)]:\n",
    "        for _ in range(num_instances):\n",
    "            initial_grid = np.random.choice(\n",
    "                vals, grid_size * grid_size, p=list(init)\n",
    "            ).reshape(grid_size, grid_size)\n",
    "            subsequent_grid = evolve_grid(initial_grid, grid_size)\n",
    "            # Flatten and concatenate the two states into one list\n",
    "            instance = np.concatenate(\n",
    "                (initial_grid.flatten(), subsequent_grid.flatten())\n",
    "            )\n",
    "            data.append(instance)\n",
    "\n",
    "    # Convert the data into a pandas DataFrame and then save as CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f\"./gol/{filename}.csv\", index=False, header=False)\n",
    "\n",
    "\n",
    "# Set new grid size and generate training and testing data\n",
    "num_train_instances = 5000\n",
    "num_test_instances = 1000\n",
    "\n",
    "# Generate and save training data\n",
    "generate_data(num_train_instances, N, \"training_data\")\n",
    "\n",
    "# Generate and save testing data\n",
    "generate_data(num_test_instances, N, \"testing_data\")\n",
    "\n",
    "# Return the paths to the saved CSV files\n",
    "training_data_path = \"./gol/training_data.csv\"\n",
    "testing_data_path = \"./gol/testing_data.csv\"\n",
    "\n",
    "(training_data_path, testing_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load CSV data and transform it\n",
    "def load_and_transform_data(file_path):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path, header=None).values\n",
    "    # Transform the data: change 255 to 1\n",
    "    data[data == 255] = 1\n",
    "    return data\n",
    "\n",
    "# Load and transform the training data as an example\n",
    "train = load_and_transform_data('./gol/training_data.csv')\n",
    "test = load_and_transform_data('./gol/testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train = train[:, : N * N]\n",
    "y_train = train[:, N * N :]\n",
    "x_test = train[:, : N * N]\n",
    "y_test = train[:, N * N :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.4379 - binary_accuracy: 0.8231 - val_loss: 0.3644 - val_binary_accuracy: 0.8236\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.3160 - binary_accuracy: 0.8514 - val_loss: 0.2626 - val_binary_accuracy: 0.8962\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.2448 - binary_accuracy: 0.8944 - val_loss: 0.2023 - val_binary_accuracy: 0.9253\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.2048 - binary_accuracy: 0.9190 - val_loss: 0.2949 - val_binary_accuracy: 0.8730\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.1843 - binary_accuracy: 0.9255 - val_loss: 0.1590 - val_binary_accuracy: 0.9376\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1755 - binary_accuracy: 0.9273 - val_loss: 0.1521 - val_binary_accuracy: 0.9388\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.1608 - binary_accuracy: 0.9332 - val_loss: 0.1889 - val_binary_accuracy: 0.9163\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1564 - binary_accuracy: 0.9335 - val_loss: 0.1414 - val_binary_accuracy: 0.9371\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.1481 - binary_accuracy: 0.9365 - val_loss: 0.1481 - val_binary_accuracy: 0.9336\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1442 - binary_accuracy: 0.9363 - val_loss: 0.1338 - val_binary_accuracy: 0.9396\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1419 - binary_accuracy: 0.9371 - val_loss: 0.1283 - val_binary_accuracy: 0.9433\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.1383 - binary_accuracy: 0.9380 - val_loss: 0.1277 - val_binary_accuracy: 0.9432\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1363 - binary_accuracy: 0.9389 - val_loss: 0.1242 - val_binary_accuracy: 0.9435\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.1369 - binary_accuracy: 0.9372 - val_loss: 0.1244 - val_binary_accuracy: 0.9434\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1291 - binary_accuracy: 0.9408 - val_loss: 0.1225 - val_binary_accuracy: 0.9433\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1297 - binary_accuracy: 0.9406 - val_loss: 0.1221 - val_binary_accuracy: 0.9431\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.1289 - binary_accuracy: 0.9405 - val_loss: 0.1469 - val_binary_accuracy: 0.9303\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1306 - binary_accuracy: 0.9396 - val_loss: 0.1210 - val_binary_accuracy: 0.9439\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1269 - binary_accuracy: 0.9411 - val_loss: 0.1243 - val_binary_accuracy: 0.9408\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 0.1290 - binary_accuracy: 0.9401 - val_loss: 0.2192 - val_binary_accuracy: 0.9016\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.1265 - binary_accuracy: 0.9410 - val_loss: 0.1208 - val_binary_accuracy: 0.9435\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 0.1249 - binary_accuracy: 0.9418 - val_loss: 0.1202 - val_binary_accuracy: 0.9440\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1247 - binary_accuracy: 0.9418 - val_loss: 0.1230 - val_binary_accuracy: 0.9437\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1243 - binary_accuracy: 0.9421"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mRMSprop(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     ],  \u001b[39m# Use BinaryAccuracy for binary classification\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Assuming x_train, y_train, x_test, and y_test are defined and correctly shaped\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     x_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(x_test, y_test),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lito/Projects/DataScience/intro-to-neural-networks/game_of_life.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m train_loss, train_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_train, y_train, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1832\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1818\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1819\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         pss_evaluation_shards\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1831\u001b[0m     )\n\u001b[0;32m-> 1832\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1833\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1834\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1835\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1836\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1837\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1838\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1839\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1840\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1841\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1842\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1843\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1844\u001b[0m )\n\u001b[1;32m   1845\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1846\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1847\u001b[0m }\n\u001b[1;32m   1848\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2269\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2270\u001b[0m             ):\n\u001b[1;32m   2271\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2272\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2273\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2274\u001b[0m                     data_handler,\n\u001b[1;32m   2275\u001b[0m                     step,\n\u001b[1;32m   2276\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2277\u001b[0m                 )\n\u001b[1;32m   2279\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2280\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4079\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4080\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4081\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    877\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    878\u001b[0m )\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[39m=\u001b[39m args \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[39m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, tracing_options\u001b[39m=\u001b[39;49mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:181\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[0;32m--> 181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    184\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:363\u001b[0m, in \u001b[0;36m_set_arg_keywords\u001b[0;34m(concrete_function)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minputs[:num_positional]:\n\u001b[1;32m    362\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     user_arg_name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(arg\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mget_attr(\u001b[39m\"\u001b[39;49m\u001b[39m_user_specified_name\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    364\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m     user_arg_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensor_arg\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Projects/DataScience/intro-to-neural-networks/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1547\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1545\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1546\u001b[0m   \u001b[39mwith\u001b[39;00m c_api_util\u001b[39m.\u001b[39mtf_buffer() \u001b[39mas\u001b[39;00m buf:   \u001b[39m# pytype: disable=wrong-arg-count\u001b[39;00m\n\u001b[0;32m-> 1547\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationGetAttrValueProto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op, name, buf)\n\u001b[1;32m   1548\u001b[0m     data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n\u001b[1;32m   1549\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1550\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "with tf.device(\"/GPU:0\"):  # Use '/CPU:0' to force it to run on CPU\n",
    "    num_cells = N * N\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Reshape((N, N, 1), input_shape=(num_cells,)))  # Reshape input to be 20x20x1\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))  # Convolutional layer\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))  # Convolutional layer\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))  # Convolutional layer\n",
    "    model.add(keras.layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same'))  # Output layer\n",
    "    model.add(keras.layers.Reshape((num_cells,)))  # Flatten the output to match Y shape\n",
    "    # model.add(\n",
    "    #     keras.layers.InputLayer(input_shape=(num_cells,))\n",
    "    # )  # Define the input shape\n",
    "    # model.add(\n",
    "    #     keras.layers.Dense(num_cells, activation=\"relu\")\n",
    "    # )  # First layer with ReLU activation\n",
    "    # model.add(\n",
    "    #     keras.layers.Dense(num_cells, activation=\"sigmoid\")\n",
    "    # )  # Output layer with sigmoid activation\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy()\n",
    "        ],  # Use BinaryAccuracy for binary classification\n",
    "    )\n",
    "\n",
    "    # Assuming x_train, y_train, x_test, and y_test are defined and correctly shaped\n",
    "    model_history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=200,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test),\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=2)\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "    print(f\"Training accuracy: {train_accuracy}, Testing accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
